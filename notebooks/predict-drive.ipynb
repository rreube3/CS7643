{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514e6971-5a90-4727-a6af-c756eb11e784",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import argparse\n",
    "from typing import Dict\n",
    "\n",
    "import torch\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from model.metrics import Metrics\n",
    "from model.unet import Unet, DEFAULT_UNET_LAYERS\n",
    "from model.dice_loss import DiceLoss, DiceBCELoss\n",
    "from datasets.dataset import RetinaSegmentationDataset\n",
    "from utils.resultPrinter import ResultPrinter\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5250eac2-5ed2-42d8-8427-bd305f5b8a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, criterion, optimizer, device):\n",
    "    metrics_tracker = Metrics(device)\n",
    "    model.train()\n",
    "    train_running_loss = 0.0\n",
    "    for ind, (img, lbl) in enumerate(tqdm(dataloader, desc=\"Training\")):\n",
    "        # Copy to device\n",
    "        img = img.to(device)\n",
    "        lbl = lbl.to(device)\n",
    "        # Make the prediction\n",
    "        lbl_pred = model(img)\n",
    "        optimizer.zero_grad()\n",
    "        # Compute loss\n",
    "        loss = criterion(lbl_pred, lbl)\n",
    "        # compute metrics\n",
    "        metrics_tracker.calculate(lbl_pred, lbl)\n",
    "        # Running tally\n",
    "        train_running_loss += loss.item() * img.shape[0]\n",
    "        # Backward step\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Compute the loss for this epoch\n",
    "    train_loss = train_running_loss / (ind + 1)\n",
    "    # Compute the metrics for this epoch\n",
    "    metrics = metrics_tracker.get_mean_metrics(ind + 1)\n",
    "    metrics['loss'] = train_loss\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843bcdf4-27b1-49a1-9bb4-f7eb223bd5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, dataloader, criterion, device):\n",
    "    metrics_tracker = Metrics(device)\n",
    "    model.eval()\n",
    "    eval_running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for ind, (img, lbl) in enumerate(tqdm(dataloader, desc=\"Validation\")):\n",
    "            # Copy to device\n",
    "            img = img.to(device)\n",
    "            lbl = lbl.to(device)\n",
    "            # Make the prediction\n",
    "            lbl_pred = model(img)\n",
    "            # Compute loss\n",
    "            loss = criterion(lbl_pred, lbl)\n",
    "            # compute metrics\n",
    "            metrics_tracker.calculate(lbl_pred, lbl)\n",
    "            # Running tally\n",
    "            eval_running_loss += loss.item() * img.shape[0]\n",
    "\n",
    "    # Compute the loss for this epoch\n",
    "    eval_loss = eval_running_loss / (ind + 1)\n",
    "    # Compute the metrics for this epoch\n",
    "    metrics = metrics_tracker.get_mean_metrics(ind + 1)\n",
    "    metrics['loss'] = eval_loss\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c86c91d-a5d6-4595-9638-a067a5c4f104",
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir: str = \"C:/Users/shawn/Desktop/Development/CS7643/data/DATA_4D_Patches/DATA_4D_Patches\"\n",
    "workers: int = 8\n",
    "load_encoder_weights: str = None\n",
    "load_bt_checkpoint: str = None\n",
    "anneal_tmax: int = 10\n",
    "anneal_eta: int = 0\n",
    "run_name: str = \"test-drive\"\n",
    "checkpoint_dir: str = \"C:/Users/shawn/Desktop/Development/CS7643/checkpoint/\"\n",
    "\n",
    "# Tune\n",
    "# 0.01\t32\tDiceLoss\t0.2\tCosineAnnealing\t16-32-64\n",
    "args = {\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"unet_layers\": \"16-32-64\",\n",
    "    \"epochs\": 10,\n",
    "    \"batch_size\": 32,\n",
    "    \"scheduler\": \"CosineAnnealing\",\n",
    "    \"loss_function\": \"DiceLoss\",\n",
    "    \"dropout\": 0.2\n",
    "}\n",
    "\n",
    "# Caleb's Random Search\n",
    "'''\n",
    "args = {\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"unet_layers\": \"64-128-256\",\n",
    "    \"epochs\": 10,\n",
    "    \"batch_size\": 64,\n",
    "    \"scheduler\": \"CosineAnnealing\",\n",
    "    \"loss_function\": \"DiceLoss\",\n",
    "    \"dropout\": 0.2\n",
    "}\n",
    "'''\n",
    "\n",
    "# Get the device\n",
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda:0\"\n",
    "\n",
    "# Determine the layer sizes of the U-Net\n",
    "unet_layers = DEFAULT_UNET_LAYERS\n",
    "if args[\"unet_layers\"]:\n",
    "    unet_layers = [int(x) for x in args[\"unet_layers\"].split(\"-\")]\n",
    "\n",
    "# Initialize the model on the GPU\n",
    "model = Unet(dropout=args[\"dropout\"], hidden_channels=unet_layers).to(device)\n",
    "if load_encoder_weights:\n",
    "    model.encoder.load_state_dict(torch.load(load_encoder_weights))\n",
    "elif load_bt_checkpoint:\n",
    "    model.encoder.load_state_dict(torch.load(load_bt_checkpoint)[\"encoder\"])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args[\"learning_rate\"])\n",
    "\n",
    "# Define scheduler (if necessary)\n",
    "scheduler = None\n",
    "if args[\"scheduler\"] == 'CosineAnnealing':\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, anneal_tmax, anneal_eta)\n",
    "elif args[\"scheduler\"] == 'ReduceOnPlateau':\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
    "\n",
    "# Select the Loss function\n",
    "loss_functions = {\n",
    "    \"BCEWithLogitsLoss\": torch.nn.BCEWithLogitsLoss(),\n",
    "    \"CrossEntropyLoss\": torch.nn.CrossEntropyLoss(),\n",
    "    \"DiceLoss\": DiceLoss(),\n",
    "    \"DiceBCELoss\": DiceBCELoss()\n",
    "}\n",
    "criterion = loss_functions[args[\"loss_function\"]]\n",
    "\n",
    "# Load the training datasets\n",
    "training_path = os.path.join(rootdir, \"Training\")\n",
    "training_file_basenames = os.listdir(os.path.join(training_path, \"images\"))\n",
    "training_dataset = RetinaSegmentationDataset(training_path, training_file_basenames)\n",
    "training_dataloader = torch.utils.data.DataLoader(\n",
    "    training_dataset, batch_size=args[\"batch_size\"], num_workers=workers,\n",
    "    pin_memory=True, shuffle=True)\n",
    "\n",
    "# Load the validation datasets\n",
    "validation_path = os.path.join(rootdir, \"Validation\")\n",
    "validation_file_basenames = os.listdir(os.path.join(validation_path, \"images\"))\n",
    "validation_dataset = RetinaSegmentationDataset(validation_path, validation_file_basenames)\n",
    "validation_dataloader = torch.utils.data.DataLoader(\n",
    "    validation_dataset, batch_size=args[\"batch_size\"], num_workers=workers,\n",
    "    pin_memory=True, shuffle=False)\n",
    "\n",
    "# Train / Val loop\n",
    "training_losses = []\n",
    "validation_losses = []\n",
    "\n",
    "# Create a descriptive name for the checkpoints\n",
    "temp_dict = dict(args)\n",
    "descrip_name = \"\"\n",
    "for key in temp_dict.keys():\n",
    "    if (key != \"rootdir\" and\n",
    "            \"load\" not in key and\n",
    "            \"checkpoint\" not in key and\n",
    "            \"workers\" not in key and\n",
    "            \"save_freq\" not in key):\n",
    "        descrip_name += \"--\" + key + \"=\" + str(temp_dict[key])\n",
    "descrip_name = descrip_name.replace(' ', '_').replace('[', '').replace(']', '').replace('\\'', '')\n",
    "\n",
    "# runs dict should be passed to each instance of a results printer. It is only appended to so should be thread safe.\n",
    "runs: Dict[str, Dict[str, float]] = {}\n",
    "# create a new results printer for each param setting tested\n",
    "result_printer = ResultPrinter(descrip_name, runs, time_label=run_name)\n",
    "\n",
    "epoch_pbar = tqdm(total=args[\"epochs\"], desc=\"Epochs\")\n",
    "\n",
    "prev_validation_loss = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ea254c",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745b3ed1-3797-476d-bbb0-b56ef8e56fad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(args[\"epochs\"]):\n",
    "\n",
    "    train_metrics = train_model(model, training_dataloader, criterion, optimizer, device)\n",
    "    result_printer.print(f'Training metrics: {str(train_metrics)}')\n",
    "    train_loss = train_metrics['loss']\n",
    "\n",
    "    validation_metrics = eval_model(model, validation_dataloader, criterion, device)\n",
    "    result_printer.print(f'Validation metrics: {str(validation_metrics)}')\n",
    "    validation_loss = validation_metrics['loss']\n",
    "\n",
    "    result_printer.rankAndSave(validation_metrics)\n",
    "\n",
    "    training_losses.append(train_loss)\n",
    "    validation_losses.append(validation_loss)\n",
    "    epoch_pbar.write(\"=\" * 80)\n",
    "    epoch_pbar.write(\"Epoch: {}\".format(i))\n",
    "    epoch_pbar.write(\"Train Loss : {:.4f}\".format(train_loss))\n",
    "    epoch_pbar.write(\"Validation Loss : {:.4f}\".format(validation_loss))\n",
    "    epoch_pbar.write(\"=\" * 80)\n",
    "    epoch_pbar.update(1)\n",
    "\n",
    "    # Save plot of Train/Validation Loss Per Epoch\n",
    "    result_printer.makePlots(training_losses, validation_losses, i)\n",
    "\n",
    "    # Take appropriate scheduler step (if necessary)\n",
    "    if args[\"scheduler\"] == 'CosineAnnealing':\n",
    "        scheduler.step()\n",
    "    elif args[\"scheduler\"] == 'ReduceOnPlateau':\n",
    "        scheduler.step(validation_loss)\n",
    "\n",
    "    if prev_validation_loss is not None:\n",
    "        if abs(prev_validation_loss - validation_loss) / prev_validation_loss < 0.01:\n",
    "            break\n",
    "\n",
    "    # if i % args.save_freq == 0:\n",
    "    # save the model\n",
    "    state = dict(epoch=i + 1,\n",
    "                 model=model.state_dict(),\n",
    "                 optimizer=optimizer.state_dict(),\n",
    "                 unet_layer_sizes=unet_layers,\n",
    "                 args=temp_dict)\n",
    "    torch.save(state, checkpoint_dir + f'unet-best-1208-{descrip_name}-epoch-{i}.pth')\n",
    "\n",
    "    prev_validation_loss = validation_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774b1704",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from img_transform.transforms import EyeMaskCustomTransform, EyeDatasetCustomTransform\n",
    "\n",
    "\n",
    "DRIVE_TRANSFORMS = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    torch.nn.ConstantPad2d((0, 75, 0, 56), 0),\n",
    "    EyeDatasetCustomTransform(mask_threshold=0.25),\n",
    "])\n",
    "\n",
    "\n",
    "# Load the validation datasets\n",
    "test_path = os.path.join(rootdir, \"Testing\")\n",
    "test_file_basenames = os.listdir(os.path.join(test_path, \"images\"))\n",
    "test_dataset = RetinaSegmentationDataset(test_path, test_file_basenames, has_labels=False, img_transforms=DRIVE_TRANSFORMS)\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=1, num_workers=1,\n",
    "    pin_memory=True, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e1bb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#state_dict = torch.load(\"..\\\\checkpoint\\\\first_submission-64-128-256.pth\")\n",
    "#model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff54030",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af19bca5-c881-46d9-9ef5-06b986706cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def predict_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for ind, (img, lbl) in enumerate(tqdm(dataloader, desc=\"Testing\")):\n",
    "            # Copy to device\n",
    "            img = img.to(device)\n",
    "            # Make the prediction\n",
    "            lbl_pred = model(img)\n",
    "            im = np.round(F.sigmoid(lbl_pred).squeeze(0).squeeze(0).cpu().detach().numpy()[:584, :565])\n",
    "            im = Image.fromarray(im.astype(np.uint8) * 255)\n",
    "            im.save(f\"C:/Users/shawn/Desktop/Development/CS7643/drive_predicted/{ind}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5595ddc4-94d7-4daa-a804-cb304a7d1f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_model(model, test_dataloader, device)\n",
    "\n",
    "result_printer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef185198",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "test = torch.Tensor(np.ones((3, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf66648f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(os.path.join(test_path, \"images\", test_file_basenames[0]), \"rb\") as f:\n",
    "    test_img = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c3d150",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787cd889",
   "metadata": {},
   "outputs": [],
   "source": [
    "565-640"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
